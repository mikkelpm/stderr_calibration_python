{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "4c877fb1",
   "metadata": {},
   "source": [
    "# Standard errors for calibrated parameters: Example\n",
    "\n",
    "Consider a simple model with two structural parameters $(\\theta_1,\\theta_2)$ and three reduced-form moments $(\\mu_1,\\mu_2,\\mu_3)$. The theoretical mapping between parameters and moments is given by\n",
    "$$\\begin{pmatrix} \\mu_1 \\\\ \\mu_2 \\\\ \\mu_3 \\end{pmatrix} =  \\begin{pmatrix} \\theta_1 \\\\ \\theta_1+\\theta_2 \\\\ 2\\theta_2 \\end{pmatrix} = h(\\theta_1,\\theta_2).$$\n",
    "\n",
    "We observe the noisy estimates $(\\hat{\\mu}_1,\\hat{\\mu}_2,\\hat{\\mu}_3) = (1.1,0.8,-0.1)$ of the true moments. The standard errors of the three empirical moments are $(\\hat{\\sigma}_1,\\hat{\\sigma}_2,\\hat{\\sigma}_3)=(0.1,0.2,0.05)$.\n",
    "\n",
    "We will estimate the parameters $(\\theta_1,\\theta_2)$ by minimum distance, matching the model-implied moments $h(\\theta_1,\\theta_2)$ to the empirical moments:\n",
    "$$\\hat{\\theta} = \\text{argmin}_{\\theta}\\; (\\hat{\\mu}-h(\\theta))'\\hat{W}(\\hat{\\mu}-h(\\theta)).$$\n",
    "\n",
    "To compute standard errors for the estimated parameters, test hypotheses, and compute the efficient weight matrix $\\hat{W}$, we use the formulas in [Cocci & Plagborg-MÃ¸ller (2023)](https://arxiv.org/abs/2109.08109), which do not require knowledge of the correlation structure of the empirical moments.\n",
    "\n",
    "## Define the model\n",
    "We first import relevant packages and define the model and data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2fff1078",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from stderr_calibration import MinDist # Minimum distance routines\n",
    "\n",
    "# Define moment function h(.)\n",
    "G = np.array([[1,0],[1,1],[0,2]])\n",
    "h = lambda theta: theta @ G.T\n",
    "\n",
    "# Define empirical moments and their s.e.\n",
    "mu = np.array([1.1,0.8,-0.1])\n",
    "sigma = np.array([0.1,0.2,0.05])\n",
    "\n",
    "# Define MinDist object used in later analysis\n",
    "obj = MinDist(h,mu,moment_se=sigma)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d9299034",
   "metadata": {},
   "source": [
    "(Note: In our simple example, we have a formula for the Jacobian of $h(\\cdot)$ with respect to the parameters. This could be supplied to the `MinDist` call using the optional argument `moment_fct_deriv`. The default behavior is to compute Jacobians numerically.)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5d21c116",
   "metadata": {},
   "source": [
    "## Initial parameter estimates and standard errors\n",
    "We first estimate the model using an *ad hoc* diagonal weight matrix $\\hat{W}=\\text{diag}(\\hat{\\sigma}_1^{-2},\\hat{\\sigma}_2^{-2},\\hat{\\sigma}_3^{-2})$. The numerical optimization for computing the estimates $(\\hat{\\theta}_1,\\hat{\\theta}_2)$ is started off at $(0,0)$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aca84fae",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "res = obj.fit(opt_init=np.zeros(2), eff=False) # eff=False: estimation based on ad hoc diagonal weight matrix\n",
    "print('Parameter estimates')\n",
    "print(res['estim'])\n",
    "print('Standard errors')\n",
    "print(res['estim_se'])\n",
    "print('\\n')\n",
    "for i in range(2):\n",
    "    print(f'Worst-case moment var-cov matrix for estimating theta_{i+1}')\n",
    "    print(res['worstcase_varcov'][i])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0796a1db",
   "metadata": {},
   "source": [
    "(Note 1: In this simple linear example, there exists a closed-form formula for the minimum distance estimator. This formula can be supplied to the `fit()` function using the optional argument `estim_fct`.)\n",
    "\n",
    "(Note 2: In some cases the minimum distance parameter estimate may have already been computed elsewhere. It can then be passed to the `fit()` function via the optional argument `param_estim`. The function will compute the corresponding standard errors without re-estimating the model.)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "868b6ffe",
   "metadata": {},
   "source": [
    "## Test of parameter restrictions\n",
    "Let us test whether the parameters $\\theta_1$ and $\\theta_2$ equal zero."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "490762c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_res = obj.test(res) # Tests are based on the \"res\" estimation results\n",
    "print('\\nt-statistics for testing individual parameters')\n",
    "print(test_res['tstat'])\n",
    "print('p-value of joint test')\n",
    "print(test_res['joint_pval'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2e0f9b5c",
   "metadata": {},
   "source": [
    "Using a 5% significance level, we cannot reject that $\\theta_2$ is zero individually based on its t-statistic. However, we can reject the joint hypothesis that both parameters equal zero.\n",
    "\n",
    "Suppose we wanted to test the joint null hypothesis that $(\\theta_1,\\theta_2)=(1,0)$. To do this, we first reformulate it as the hypothesis that the transformed vector $r(\\theta_1,\\theta_2)=(\\theta_1-1,\\theta_2)$ has all elements equal to zero. We can then test the hypothesis as follows."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3eb4acad",
   "metadata": {},
   "outputs": [],
   "source": [
    "r = lambda theta: theta-np.array([1,0]) # Restriction function\n",
    "res_restr = obj.fit(transf=r, opt_init=res['estim'], eff=False) # Estimate the transformation r(theta)\n",
    "test_res2 = obj.test(res_restr) # Test using the restriction function\n",
    "print('\\np-value of joint test')\n",
    "print(test_res2['joint_pval'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e7b00945",
   "metadata": {},
   "source": [
    "## Over-identification test\n",
    "Since we have more moments (3) than parameters (2), we can test the over-identifying restriction. One common way of doing this in applied work is to estimate the model using only two of the moments and then checking whether the third, non-targeted moment at the estimated parameters is approximately consistent with the data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1dac862f",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "weight_mat = np.diag(np.array([1/sigma[0]**2, 1/sigma[1]**2, 0])) # Weight matrix that puts no weight on third moment\n",
    "res_justid = obj.fit(opt_init=np.zeros(2), eff=False, weight_mat=weight_mat)\n",
    "print('Just-identified parameter estimates')\n",
    "print(res_justid['estim'])\n",
    "print('Model-implied moments')\n",
    "print(res_justid['moment_fit'])\n",
    "print('\\n')\n",
    "\n",
    "res_overid = obj.overid(res_justid) # Over-identification test based on just-identified estimates\n",
    "print('\\nError in matching non-targeted moment')\n",
    "print(res_overid['moment_error'][2]) # The non-targeted moment is the third one\n",
    "print('Standard error')\n",
    "print(res_overid['moment_error_se'][2])\n",
    "print('t-statistic')\n",
    "print(res_overid['tstat'][2])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "34df68f4",
   "metadata": {},
   "source": [
    "Since the t-statistic is below 1.96, we can't reject the validity of the model at the 5% level."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5a0d8615",
   "metadata": {},
   "source": [
    "## Efficient estimation\n",
    "The above estimation results relied on an *ad hoc* diagonal weight matrix. We can compute the weight matrix that minimizes the worst-case standard errors, and then report the corresponding estimates and standard errors."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "55f42ce3",
   "metadata": {},
   "outputs": [],
   "source": [
    "res_eff = obj.fit(opt_init=np.zeros(2), eff=True) # Note: Efficient estimation (eff=True) is the default\n",
    "print('Efficient parameter estimates')\n",
    "print(res_eff['estim'])\n",
    "print('Efficient standard errors')\n",
    "print(res_eff['estim_se'])\n",
    "print('\\n')\n",
    "\n",
    "for i in range(2):\n",
    "    print(f'Efficient moment loadings for estimating theta_{i+1}')\n",
    "    print(res_eff['moment_loadings'][:,i])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1c1b5e88",
   "metadata": {},
   "source": [
    "We see that $\\theta_1$ is estimated off the 1st moment only, while $\\theta_2$ is estimated off the 3rd moment only (up to small numerical error).\n",
    "\n",
    "(Note: The efficient estimates are not based on a single choice of weight matrix, since the efficient weight matrix depends on the specific parameter of interest. In the background, the analysis is actually run separately for each parameter. For this reason, it is not advised to use the `test()` or `overid()` commands with efficient estimation results. These commands are better used with estimation results that correspond to a single choice of weight matrix.)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c40b4777",
   "metadata": {},
   "source": [
    "## Inference about transformed parameters\n",
    "Suppose we want a confidence interval for the transformed parameter $\\theta_1^2+\\theta_2$. In a more realistic setting, this parameter might be some model-implied counterfactual of interest. We can do inference on transformed parameters using the `transf` argument to the `fit` function, as already used above."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "156319fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "res_transf = obj.fit(transf=lambda theta: theta[0]**2+theta[1], opt_init=np.zeros(2)) # Efficient estimation (the default)\n",
    "print('Estimated transformation')\n",
    "print(res_transf['estim'])\n",
    "print('Standard errors')\n",
    "print(res_transf['estim_se'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "587834d2",
   "metadata": {},
   "source": [
    "(Note: If the gradient of the transformed parameter is available, we can supply it to the `fit()` function using the optional `transf_deriv` argument.)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0f824403",
   "metadata": {},
   "source": [
    "## More information about the variance-covariance matrix\n",
    "Suppose we happen to also know that the first two empirical moments $\\hat{\\mu}_1$ and $\\hat{\\mu}_2$ are (asymptotically) independent. We can use this information to sharpen our inference about the parameters. First we define the known and unknown parts of the var-cov matrix of the empirical moments."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "10bcdcd8",
   "metadata": {},
   "outputs": [],
   "source": [
    "V = np.array([[sigma[0]**2,0,np.nan],[0,sigma[1]**2,np.nan],[np.nan,np.nan,sigma[2]**2]]) # NaN values are unknown\n",
    "print('Var-cov matrix of moments')\n",
    "print(V)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cf3de6cc",
   "metadata": {},
   "source": [
    "Then we define a `MinDist` object using this var-cov matrix and apply the estimation/testing routines."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "96599b4f",
   "metadata": {},
   "outputs": [],
   "source": [
    "obj_moreinfo = MinDist(h,mu,moment_varcov=V)\n",
    "res_moreinfo = obj_moreinfo.fit(opt_init=np.zeros(2), eff=False)\n",
    "print('Initial estimates')\n",
    "print(res_moreinfo['estim'])\n",
    "print('Standard errors')\n",
    "print(res_moreinfo['estim_se'])\n",
    "\n",
    "res_eff_moreinfo = obj_moreinfo.fit(opt_init=np.zeros(2), eff=True)\n",
    "print('\\nEfficient estimates')\n",
    "print(res_eff_moreinfo['estim'])\n",
    "print('Standard errors')\n",
    "print(res_eff_moreinfo['estim_se'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fe79139e",
   "metadata": {},
   "source": [
    "## Full-information analysis\n",
    "Suppose finally that we know the entire var-cov matrix of the empirical moments. For example:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "91f1950b",
   "metadata": {},
   "outputs": [],
   "source": [
    "V_fullinfo = sigma.reshape(-1,1) * np.array([[1,0,0.5],[0,1,-0.7],[0.5,-0.7,1]]) * sigma\n",
    "print('Var-cov matrix of moments')\n",
    "print(V_fullinfo)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "397c0588",
   "metadata": {},
   "source": [
    "In this full-information setting, the econometric analysis is standard ([Newey & McFadden, 1994](https://doi.org/10.1016/S1573-4412%2805%2980005-4)). The estimation and testing routines work as before."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1647540a",
   "metadata": {},
   "outputs": [],
   "source": [
    "obj_fullinfo = MinDist(h,mu,moment_varcov=V_fullinfo)\n",
    "res_fullinfo = obj_fullinfo.fit(opt_init=np.zeros(2), weight_mat=np.diag(sigma**(-2)), eff=False) # Diagonal weight matrix\n",
    "print('Initial estimates')\n",
    "print(res_fullinfo['estim'])\n",
    "print('Standard errors')\n",
    "print(res_fullinfo['estim_se'])\n",
    "\n",
    "res_eff_fullinfo = obj_fullinfo.fit(opt_init=np.zeros(2), eff=True) # Efficient weight matrix\n",
    "print('\\nEfficient estimates')\n",
    "print(res_eff_fullinfo['estim'])\n",
    "print('Standard errors')\n",
    "print(res_eff_fullinfo['estim_se'])\n",
    "\n",
    "test_res_fullinfo = obj_fullinfo.test(res_eff_fullinfo)\n",
    "print('\\np-value for joint test that both parameters are zero')\n",
    "print(test_res_fullinfo['joint_pval'])\n",
    "\n",
    "overid_res_fullinfo = obj_fullinfo.overid(res_eff_fullinfo)\n",
    "print('p-value for over-identification test')\n",
    "print(overid_res_fullinfo['joint_pval'])\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
